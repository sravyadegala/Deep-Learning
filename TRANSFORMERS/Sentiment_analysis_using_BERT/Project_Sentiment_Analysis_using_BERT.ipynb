{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project: Sentiment Analysis using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef52db4fdc5a4ea8bf841ef0dea0871e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_810a9fd3b49b4414a6847d3a1f2e6078",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10abd0a5d356443e868c375e2f0e2993",
              "IPY_MODEL_2b5aee5a36954d92ba3eb5359a9f638e"
            ]
          }
        },
        "810a9fd3b49b4414a6847d3a1f2e6078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10abd0a5d356443e868c375e2f0e2993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe9d2d439da74952b43384c9e821ee33",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95fcd101ff3d4a688ac5da1c5bb2c0b1"
          }
        },
        "2b5aee5a36954d92ba3eb5359a9f638e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_978f2b33b84e4dd3a201334779e4ebf4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:07&lt;00:00, 61.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_855dbdc2882f4affa5f773b201d362d0"
          }
        },
        "fe9d2d439da74952b43384c9e821ee33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95fcd101ff3d4a688ac5da1c5bb2c0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "978f2b33b84e4dd3a201334779e4ebf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "855dbdc2882f4affa5f773b201d362d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b2e61972db34d27bc8f82745046fb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba3933f4aa844c9195429d7bdc2c2131",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df14545162f9426a81841b0251d15e37",
              "IPY_MODEL_a61a7174dae347e68cfc9a5814091765"
            ]
          }
        },
        "ba3933f4aa844c9195429d7bdc2c2131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df14545162f9426a81841b0251d15e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b71fbb2656f845c982c0a0f6acfde476",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92180babc6354d90a68f6e84417fa9a6"
          }
        },
        "a61a7174dae347e68cfc9a5814091765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7afdabd747f14d4f99141a969d2a5616",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 64.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c147562f2fb4f84891ef913a4c69d4f"
          }
        },
        "b71fbb2656f845c982c0a0f6acfde476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92180babc6354d90a68f6e84417fa9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7afdabd747f14d4f99141a969d2a5616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c147562f2fb4f84891ef913a4c69d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d74892f3fb5e48a683397f70f8b0ba17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52457c9c24804839a0e660d1532682ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f2e72143d124543b4327ff965a62e76",
              "IPY_MODEL_90703662acfc4619bcc7d0a108cbc259"
            ]
          }
        },
        "52457c9c24804839a0e660d1532682ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f2e72143d124543b4327ff965a62e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82fb22954c2b4f169525db85f54af6f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_704bf5c8598348dead1b62501b73d3d8"
          }
        },
        "90703662acfc4619bcc7d0a108cbc259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8bbec845a0f443e68c73cbcf733b37b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [01:48&lt;00:00, 2.13kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec66ebf0d1bc49548306740fb1b0ed8a"
          }
        },
        "82fb22954c2b4f169525db85f54af6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "704bf5c8598348dead1b62501b73d3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bbec845a0f443e68c73cbcf733b37b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec66ebf0d1bc49548306740fb1b0ed8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2ef46721a5247ee9bd7e6cc9eb61456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f3580e252ac480e8ef59ddc960d5770",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b801acba13d14924bce808c23e8e341d",
              "IPY_MODEL_93320db1387b40b0898b6fb4768282e7"
            ]
          }
        },
        "2f3580e252ac480e8ef59ddc960d5770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b801acba13d14924bce808c23e8e341d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b66eee0d9f2467983da58016cc901fa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14640,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14640,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cbe942717164b31b28b1b93f6de56a8"
          }
        },
        "93320db1387b40b0898b6fb4768282e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35077ceb4a2c44b0a2951c8eacc949cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14640/14640 [01:38&lt;00:00, 148.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_785ee85f26984af0b4a7ae5fccef3931"
          }
        },
        "0b66eee0d9f2467983da58016cc901fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cbe942717164b31b28b1b93f6de56a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35077ceb4a2c44b0a2951c8eacc949cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "785ee85f26984af0b4a7ae5fccef3931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPV6GD0oXtQk",
        "colab_type": "text"
      },
      "source": [
        "# Objective\n",
        "\n",
        "In this notebook, we will fine-tune a pre-trained BERT model to perform sentiment analysis on a twitter data.\n",
        "\n",
        "# Table of Contents\n",
        "\n",
        "1. Setup\n",
        "  - Using Google Colab for training\n",
        "  - Installing the Hugging Face's Transformers Library\n",
        "2. Loading & Understanding BERT\n",
        "  - Download Pretrained BERT model\n",
        "  - Tokenization and Input Formatting\n",
        "  - Understanding Input and Output\n",
        "3. Preparing Data\n",
        "  - Loading and Reading Twitter Airline\n",
        "  - Text Cleaning\n",
        "  - Preparing Input and Output Data\n",
        "  - Training and Validation Data\n",
        "  - Define Dataloaders\n",
        "4. Model Finetuning\n",
        "  - Approach: Fine-Tuning Only Head\n",
        "  - Define Model Architecture\n",
        "  - Define Optimizer and Loss function\n",
        "  - Model Training and Evaluation\n",
        "  - Train the Model\n",
        "  - Model Evaluation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLnXNGquujFX",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5dWVBhsvBpB",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Using Google Colab for training\n",
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we are going to train a large neural network, it's best to take advantage of the GPU/TPU (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QUIh1DwGdK",
        "colab_type": "text"
      },
      "source": [
        "We will identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plFhDqWS7IDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ae67f03-bcb2-483e-db59-dc592752bc90"
      },
      "source": [
        "#import torch library\n",
        "import torch\n",
        "\n",
        "# check GPU availability\n",
        "if torch.cuda.is_available():    \n",
        "    # select GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qksck1C7e3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a33cd54a-a98a-41ad-8ced-fe3905879861"
      },
      "source": [
        "# check GPU name\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL4kE0e9xyl0",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Installing the Hugging Face's Transformers Library\n",
        "\n",
        "Hugging Face ü§ó is the one of the most popular Natural Language Processing communities for deep learning researchers, hands-on practitioners and educators. It provides State of Art architectures for everyone.\n",
        "\n",
        "\n",
        "The Transformers library (formerly known as pytorch-transformers) provides a wide range of general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, etc) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with a wide range of pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jdjScBvG-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "8aac8587-0041-4e11-8de0-cdb0b267918e"
      },
      "source": [
        "#install hugging face transformers\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |‚ñç                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |‚ñâ                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñé                              | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñä                              | 40kB 4.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñè                             | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñã                             | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñç                            | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñâ                            | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñé                           | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñä                           | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 184kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 194kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 204kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 215kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 225kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 235kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 245kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 256kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 266kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 276kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 286kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 296kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 307kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 317kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 327kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 337kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 348kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 358kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 368kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 378kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 389kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 399kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 409kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 419kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 430kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 440kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 450kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 460kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 471kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 481kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 491kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 501kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 512kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 522kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 532kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 542kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 552kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 563kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 573kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 583kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 593kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 604kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 614kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 624kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 634kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 645kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 655kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 665kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 675kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 686kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 696kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 706kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 716kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 727kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 737kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 747kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 757kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 768kB 5.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 778kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1MB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0MB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=96a7895687fabdc99603d071c0e4c96c12b8d225891507146da1692156aef9f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eLFxRkQL1R",
        "colab_type": "text"
      },
      "source": [
        "# 2. Loading & Understanding BERT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M1sab_G9bOl",
        "colab_type": "text"
      },
      "source": [
        "##2.1 Download Pretrained BERT model\n",
        "\n",
        "We will use the uncased pre-trained version of the BERT base model. It was trained on lower-cased English text. \n",
        "\n",
        "You can find more pre-trained models here https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZGp7pmiIa42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "ef52db4fdc5a4ea8bf841ef0dea0871e",
            "810a9fd3b49b4414a6847d3a1f2e6078",
            "10abd0a5d356443e868c375e2f0e2993",
            "2b5aee5a36954d92ba3eb5359a9f638e",
            "fe9d2d439da74952b43384c9e821ee33",
            "95fcd101ff3d4a688ac5da1c5bb2c0b1",
            "978f2b33b84e4dd3a201334779e4ebf4",
            "855dbdc2882f4affa5f773b201d362d0",
            "7b2e61972db34d27bc8f82745046fb98",
            "ba3933f4aa844c9195429d7bdc2c2131",
            "df14545162f9426a81841b0251d15e37",
            "a61a7174dae347e68cfc9a5814091765",
            "b71fbb2656f845c982c0a0f6acfde476",
            "92180babc6354d90a68f6e84417fa9a6",
            "7afdabd747f14d4f99141a969d2a5616",
            "4c147562f2fb4f84891ef913a4c69d4f"
          ]
        },
        "outputId": "c23e9be9-9393-4566-932f-b1889b25dac1"
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# download bert pretrained model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef52db4fdc5a4ea8bf841ef0dea0871e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2e61972db34d27bc8f82745046fb98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzkcvW6F5aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c42e74d0-2553-4a54-ea77-4d5ba607045f"
      },
      "source": [
        "# print bert architecture\n",
        "print(bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGt3oSZ4fzZ",
        "colab_type": "text"
      },
      "source": [
        "##2.2 Tokenization and Input Formatting\n",
        "\n",
        "**Download BERT Tokenizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCZVXkA30cf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d74892f3fb5e48a683397f70f8b0ba17",
            "52457c9c24804839a0e660d1532682ac",
            "2f2e72143d124543b4327ff965a62e76",
            "90703662acfc4619bcc7d0a108cbc259",
            "82fb22954c2b4f169525db85f54af6f3",
            "704bf5c8598348dead1b62501b73d3d8",
            "8bbec845a0f443e68c73cbcf733b37b7",
            "ec66ebf0d1bc49548306740fb1b0ed8a"
          ]
        },
        "outputId": "4b464764-f4ec-48a9-c01c-6574e77e26f0"
      },
      "source": [
        "#importing fast \"BERT\" tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d74892f3fb5e48a683397f70f8b0ba17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosuQLl15olj",
        "colab_type": "text"
      },
      "source": [
        "**Steps Followed for Input Formatting**\n",
        "\n",
        "1. Tokenization\n",
        "\n",
        "2. Special Tokens\n",
        "\n",
        "  * Prepend the `[CLS]` token to the start of the sequence.\n",
        "  * Append the `[SEP]` token to the end of the sequence.\n",
        "\n",
        "3. Pad sequences \n",
        "\n",
        "4. Converting tokens to integers\n",
        "\n",
        "5. Create Attention masks to avoid pad tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBNXOU_BVj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c5241c6-397e-48ee-b661-70fca2a64226"
      },
      "source": [
        "#input text\n",
        "text = \"Jim Henson was a puppeteer\"\n",
        "\n",
        "sent_id = tokenizer.encode(text, \n",
        "                           # add [CLS] and [SEP] tokens\n",
        "                           add_special_tokens=True,\n",
        "                           # specify maximum length for the sequences                                  \n",
        "                           max_length = 10,\n",
        "                           truncation = True,\n",
        "                           # add pad tokens to the right side of the sequence\n",
        "                           pad_to_max_length='right')\n",
        "                           \n",
        "# print integer sequence\n",
        "print(\"Integer Sequence: {}\".format(sent_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer Sequence: [101, 3958, 27227, 2001, 1037, 13997, 11510, 102, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH_fCLgKt9I-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "521668b6-f72b-461b-9a84-c49543801425"
      },
      "source": [
        "# convert integers back to text\n",
        "print(\"Tokenized Text:\",tokenizer.convert_ids_to_tokens(sent_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized Text: ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQRb3ghOufP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51a4b69f-97e1-45c9-b71d-306eb3f90a8e"
      },
      "source": [
        "# decode the tokenized text\n",
        "decoded = tokenizer.decode(sent_id)\n",
        "print(\"Decoded String: {}\".format(decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoded String: [CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4HGTu_RAOof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9623c164-ad57-4590-f94d-f85550bbcad2"
      },
      "source": [
        "# mask to avoid performing attention on padding token indices. \n",
        "# mask values: 1 for tokens that are NOT MASKED, 0 for MASKED tokens.   \n",
        "att_mask = [int(tok > 0) for tok in sent_id]\n",
        "\n",
        "print(\"Attention Mask:\",att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF2MqKaT69Iz",
        "colab_type": "text"
      },
      "source": [
        "##2.3 Understanding Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IcDHx93CJnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31331bbf-8a8b-44c8-88fc-ec45e8c77509"
      },
      "source": [
        "# convert lists to tensors\n",
        "sent_id = torch.tensor(sent_id)\n",
        "att_mask = torch.tensor(att_mask)\n",
        "\n",
        "# reshaping tensor in form of (batch,text length)\n",
        "sent_id = sent_id.unsqueeze(0)\n",
        "att_mask = att_mask.unsqueeze(0)\n",
        "\n",
        "# reshaped tensor\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv3ebAJVBoMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pass integer sequence to bert model\n",
        "outputs = bert(sent_id, attention_mask=att_mask)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLtc7RRzzc0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f83cca37-63d9-4708-cfc4-4fc22b5a7e06"
      },
      "source": [
        "## unpack the ouput of bert model\n",
        "\n",
        "# hidden states at each timestep\n",
        "all_hidden_states = outputs[0]\n",
        "# hidden states at first timestep ([CLS] token)\n",
        "cls_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of last hidden states:\",all_hidden_states.shape)\n",
        "print(\"Shape of CLS hidden state:\",cls_hidden_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of last hidden states: torch.Size([1, 10, 768])\n",
            "Shape of CLS hidden state: torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xTpvKwfSlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74420da5-0471-4724-a246-6cd3a5df142b"
      },
      "source": [
        "cls_hidden_state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
              "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
              "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
              "          0.3924,  0.6863, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
              "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
              "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
              "         -0.8711,  0.0508,  0.0505, -0.1635,  0.1716,  0.4363,  0.4330, -0.0333,\n",
              "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
              "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
              "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
              "         -0.0401,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
              "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
              "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
              "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
              "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
              "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
              "         -0.1696, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
              "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
              "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
              "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
              "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
              "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2165, -0.9851, -0.4444,  0.5759,\n",
              "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
              "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
              "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2186,  0.5282, -0.3149, -0.4375,\n",
              "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
              "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
              "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
              "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
              "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
              "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
              "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
              "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
              "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
              "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
              "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
              "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
              "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
              "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
              "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
              "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
              "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
              "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
              "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
              "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
              "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
              "          0.9268, -0.4224, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
              "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
              "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
              "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
              "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
              "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
              "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
              "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
              "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
              "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
              "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
              "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
              "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
              "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
              "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
              "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
              "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
              "         -0.9936, -0.1999, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
              "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
              "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
              "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
              "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
              "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1412,\n",
              "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
              "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
              "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
              "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
              "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
              "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
              "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
              "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
              "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0723,\n",
              "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
              "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
              "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
              "          0.3962, -0.5013, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
              "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
              "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
              "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
              "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
              "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
              "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
              "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
              "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
              "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
              "          0.1236, -0.3705, -0.3958, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
              "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
              "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
              "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
              "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
              "       grad_fn=<TanhBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQj1-E2pQY6H",
        "colab_type": "text"
      },
      "source": [
        "#3. Preparing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGQamTe3ebu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##3.1 Loading and Reading Twitter Airline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqhY4dyIKJIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93688949-5123-4c5f-ea57-2173f30d1530"
      },
      "source": [
        "# upload the data and extract the file\n",
        "!unzip 'Airline_Tweets.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Airline_Tweets.zip\n",
            "  inflating: Tweets.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHLW3M3KJEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "a6e1fe97-3939-4dae-eba7-dd28e1ad46b8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# read CSV file\n",
        "df = pd.read_csv('Tweets.csv')\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzLKBEuUKJAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e9ab56a-02fe-467e-868d-9c5cfc9b1efd"
      },
      "source": [
        "#shape of the dataframe\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36CP54lLf2gA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "905f8541-afb2-46c1-bfd3-5bfa9f366296"
      },
      "source": [
        "df['text'].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4837                                                                                @SouthwestAir how do I get a companion pass\n",
              "2874                                                           @united Looks like they came through. Thanks again for the help.\n",
              "8393                               @JetBlue no, but we're on the flight leaving from Boston to Seattle right now. :) flight 597\n",
              "1624    ‚Äú@united: @rikrik__ What made you come to this? Can we help you with anything? ^JP‚Äù the service just hasn't been great.\n",
              "6882                                                                  @JetBlue - Definitely no note from whoever stole from me.\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GirJa9_sWJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "379d8062-867d-458d-fe5d-ba69aa23f1c2"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWcEVUWIMGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f212dd4a-7c43-4d56-b00e-010fed69d23b"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.626913\n",
              "neutral     0.211680\n",
              "positive    0.161407\n",
              "Name: airline_sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ArDZS9tVuPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the value counts to a list\n",
        "class_counts = df['airline_sentiment'].value_counts().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWWstFVe3x00",
        "colab_type": "text"
      },
      "source": [
        "##3.2 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ol7s5sTGUgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#library for pattern matching\n",
        "import re\n",
        "\n",
        "#define a function for text cleaning\n",
        "def preprocessor(text):\n",
        "  \n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
        "  \n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
        "  \n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "  \n",
        "  #split token to remove extra spaces\n",
        "  tokens = text.split()\n",
        "  \n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLsz50lCnXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(preprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEnvlwJdz9-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['airline_sentiment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qq7aLst01a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "65c3010a-8e83-43c0-8945-4430cb9bbc86"
      },
      "source": [
        "#cleaned text\n",
        "text[50:55]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['is flight 769 on it\\'s way? was supposed to take off 30 minutes ago. website still shows \"on time\" not \"in flight\". thanks.',\n",
              "       'julie andrews all the way though was very impressive! no to',\n",
              "       'wish you flew out of atlanta... soon?',\n",
              "       'julie andrews. hands down.',\n",
              "       'will flights be leaving dallas for la on february 24th?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbVmXPN_ao6",
        "colab_type": "text"
      },
      "source": [
        "##3.3 Preparing Input and Output Data\n",
        "\n",
        "\n",
        "**Preparing Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzd8-2P0l3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOF8XUDWuHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "143229cf-e334-4c36-dcbf-cd24d45cec57"
      },
      "source": [
        "#classes\n",
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBFVkRgoDX_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb97eb8-aec4-4124-a922-00dae7da4790"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKh8Rcuw_vOt",
        "colab_type": "text"
      },
      "source": [
        "**Preparing Input Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUFCQkM0-Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "dbf83357-8d17-464e-91ff-3286bb0b4122"
      },
      "source": [
        "# library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute no. of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "plt.hist(num, bins = 30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram: Length of sentences')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0bMmY6M0-Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define maximum length of a text\n",
        "max_len = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbV1OazzSnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b2ef46721a5247ee9bd7e6cc9eb61456",
            "2f3580e252ac480e8ef59ddc960d5770",
            "b801acba13d14924bce808c23e8e341d",
            "93320db1387b40b0898b6fb4768282e7",
            "0b66eee0d9f2467983da58016cc901fa",
            "2cbe942717164b31b28b1b93f6de56a8",
            "35077ceb4a2c44b0a2951c8eacc949cb",
            "785ee85f26984af0b4a7ae5fccef3931"
          ]
        },
        "outputId": "9b502249-8b5a-4a81-bcfe-0a420b892ff8"
      },
      "source": [
        "# library for progress bar\n",
        "from tqdm import notebook\n",
        "\n",
        "# create an empty list to save integer sequence\n",
        "sent_id = []\n",
        "\n",
        "# iterate over each tweet\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "  \n",
        "  encoded_sent = tokenizer.encode(text[i],                      \n",
        "                                  add_special_tokens = True,    \n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,         \n",
        "                                  pad_to_max_length='right')    \n",
        "  \n",
        "  # saving integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2ef46721a5247ee9bd7e6cc9eb61456",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14640.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgp93PgwLg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86c0f4e-12c1-4912-88c8-4d6ba1e9ff27"
      },
      "source": [
        "print(\"Integer Sequence:\",sent_id[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer Sequence: [101, 2054, 2056, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73WKt0NxpeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# for each sentence...\n",
        "for sent in sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "  \n",
        "  # store the attention mask for this sentence.\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONLj9J9AXQN",
        "colab_type": "text"
      },
      "source": [
        "##3.4 Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqg2GTsqxpuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y42CmxNaAsbZ",
        "colab_type": "text"
      },
      "source": [
        "##3.5 Define Dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033DKuEizSuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPnDd5SCzWS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "#Dataset wrapping tensors.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "#define a sampler for sampling the data during training\n",
        "  #random sampler samples randomly from a dataset \n",
        "  #sequential sampler samples sequentially, always in the same order\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "#represents a iterator over a dataset. Supports batching, customized data loading order\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "#Dataset wrapping tensors.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "#define a sequential sampler \n",
        "#This samples data in a sequential order\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "\n",
        "#create a iterator over the dataset\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFO9vX1WD5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "sent_id, mask, target=iterator.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek5ie3hqF7Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "362d7a32-d649-410a-8b3b-a1ab9f84eddb"
      },
      "source": [
        "sent_id.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELWRXJV0F1vm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7310e87-09f0-40da-e095-99940d1128c1"
      },
      "source": [
        "sent_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  5064,  2090,  1040,  2546,  2860,  1998,  8764,  1045,  2288,\n",
              "         19030,  2013,  2260,  2497,  2035,  1996,  2126,  2000,  4601,  2290,\n",
              "          2006, 20304,  2475,  1029,   102],\n",
              "        [  101,  2129,  2055,  2070,  4086, 19430,  3642,  2000,  2393,  2033,\n",
              "          3942,  2026,  2155,   999,   999,   999,  1012,  1012,  1012,  1012,\n",
              "          3531,   999,   999,   999,   102],\n",
              "        [  101,  7987, 27225,  1523,  1024,  2735,  2091,  2005,  2054,  1012,\n",
              "          1001,  1058,  2595,  3736,  7959,  3723, 25514,  1524,   102,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  4931,  4364,  1010,  2339,  2106,  2026,  2197,  3462,  7796,\n",
              "          2033,  1014, 19637,  1029,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  3357,  1015,  1024,  2022,  2625,  2915,  1012,  3357,  1016,\n",
              "          1024, 13399,  6304,  2060,  3182,  2084, 10474,  1012,  3357,  1017,\n",
              "          1024,  2123,  1005,  1056,   102],\n",
              "        [  101,  6146,  2581,  3823,  2013,  7921,  2012,  6921,  3199,  1999,\n",
              "          2258,  2286,  1001, 20704, 18372,  2243,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  3403,  2012,  6522,  2078,  2006,  4946,  2062,  2084,  2019,\n",
              "          3178,  2144,  4899,  1038,  1013,  1039,  1997,  2053,  4796,  1010,\n",
              "          3531,  2131,  2149,  2125,   102],\n",
              "        [  101,  2024,  2017, 14763,  2005,  3462, 26727,  2157,  2085,   102,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2003,  1996,  4037,  2091,  1029,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  1045,  1005,  1049,  2667,  2000,  4638,  2046,  2026,  2184,\n",
              "          1024,  2753,  3286, 14931,  3462,  1056,  7382,  2006,  1996, 15363,\n",
              "          4037,  1998,  2009,  1005,   102],\n",
              "        [  101,  1040,  7583,  1996,  2171,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  1523,  1024,  3376,  2915,  1012,  1012,  4283,  2005,  6631,\n",
              "          1012,  2478,  1001,  4875,  8873,  2000,  2695,  1029,  1025,  1007,\n",
              "          1524,  2115,  6160,   999,   102],\n",
              "        [  101,  2058,  1016,  2847,  1998,  2403,  2781,  2006,  2907,  1998,\n",
              "         10320,  1012,  4283,  2005,  1996,  2393,   999,  1001,  6304,  2121,\n",
              "          7903,  2063,  1001, 12077,   102],\n",
              "        [  101,  1045,  2052,  2293,  2000,  2175,  2000,  1996,  5865,  2265,\n",
              "          1625,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2057,  1005,  2310,  1006,  3462,  4008, 23777,  1007,  2042,\n",
              "          3564,  2006,  1996, 16985, 22911,  1997,  5887,  2050,  2005,  1037,\n",
              "          2096,  2085,  3403,  2006,   102],\n",
              "        [  101, 15536,  8873,  2347,  1005,  1056,  2551, 27120,  1012, 22333,\n",
              "         16742,  2128, 22278,  1012,  2017,  2741,  2033,  2000,  1037,  3309,\n",
              "          2005,  2484,  2847,  2007,   102],\n",
              "        [  101,  2293,  2129,  2017,  2064,  1005,  1056,  2131,  2019,  4005,\n",
              "          2006,  1996,  3042,  1998,  1996, 12978,  2291, 17991,  2039,  2006,\n",
              "          2017,   102,     0,     0,     0],\n",
              "        [  101,  1045,  4741,  2006,  2907,  2005,  2048,  2847,  1010,  2069,\n",
              "          2000,  2031,  2026,  2655,  1012,  2428, 23579,  1012,   102,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2748,  1012,  1045,  6618,  2019,  3178,  2001,  1037,  2146,\n",
              "          2438,  2051,  2000,  2907,  2077,  3228,  2039,  1012,  2064,  8307,\n",
              "          2655,  2033,  1029,   102,     0],\n",
              "        [  101,  1011, 10885,  2420,  1024,  7882,  1010, 15544,  5753,  1999,\n",
              "         10975,  2005,  1996,  2305,  1024,  1002,  6352,  1010,  3974,  1037,\n",
              "          2154,  2000, 28781,  1998,   102],\n",
              "        [  101, 13970, 12269,  2005,  2025,  8014,  3462,  2989,  7599,  2013,\n",
              "          1040,  2546,  2860,  2023,  2851,  1012,  2142,  2788,  2034,  2000,\n",
              "          6634,  1012,  1012,  1012,   102],\n",
              "        [  101,  2044,  2035,  1045,  2031,  2042,  2083,  2006,  2023,  4440,\n",
              "          1010,  2064,  2017,  2131,  2033,  2006,  2178,  8582,  2188,  1029,\n",
              "           102,     0,     0,     0,     0],\n",
              "        [  101,  4931,  2045,  2033,  2153,  2013,  7483, 10047,  2145,  2006,\n",
              "          2907,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2045,  2003,  2242,  3308,  2007,  2017,  4037,  1999, 23591,\n",
              "         18059,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2003,  1996,  2190,  2126,  2000,  2128,  1011, 15908,  2033,\n",
              "          2007,  2026,  2028,  2995,  2293,  1010,  6023,  1999,  3915,  1005,\n",
              "          1055,  4827,  3007,  1001,   102],\n",
              "        [  101,  4223,  2003,  2200,  4129,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  1040,  2386,  6914,  1012,  4012,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2009,  1005,  1055,  9145,  2108,  2006,  2907,  2000,  2017,\n",
              "           999,   999,  2428,  2423,  2781,  2000,  2689,  1037,  3462,   999,\n",
              "           999,   102,     0,     0,     0],\n",
              "        [  101,  6228,  3277,  1012,  3504,  2066,  2027,  2288,  2009,  4964,\n",
              "           999,  4283,  2005,  2115,  5142,  1012,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2092,  2049,  2340,  1024,  3429,  3286,  1998,  2074,  2288,\n",
              "          2019, 10373,  2008,  2026,  2340,  3286,  3462,  2003,  8394,  1011,\n",
              "          2008,  2015,  2025,  2157,   102],\n",
              "        [  101,  4067,  2017,  2005, 14120,  1012,  1012,  1012,  2026, 12191,\n",
              "          2003,  1999,  2026,  4524,  1998,  1045,  2342,  2009,  2005,  2147,\n",
              "          1012,  1045,  2572,  5191,   102],\n",
              "        [  101,  7864,  1010,  5327,  2005,  4248,  3247,  1010,  5079,  2000,\n",
              "          2178, 13445,  2057,  2074,  2363,  1024,  6378,  1011, 15045,  3296,\n",
              "         16122,  8917,  1011,  5391,   102]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ88suqBjeuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id,             #integer sequence\n",
        "               attention_mask=mask) #attention masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleBnOAn5V7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7cc27f92-aec5-457c-beac-25483ac74135"
      },
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Hidden States: torch.Size([32, 25, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb189wFSR0cE",
        "colab_type": "text"
      },
      "source": [
        "#4. Model Finetuning \n",
        "\n",
        "*The pretrained model is trained on the general domain corpus. So, finetuning the pretrained model helps in the capturing the domain specific features from our custom dataset*\n",
        "\n",
        "\n",
        "Every pretrained model is trained using 2 different layers : **BackBone and Head** \n",
        "\n",
        "* Backbone refers to the pretrained model architecture \n",
        "* Head refers to the dense layer added on top of backbone. Generally, this layer is used for the classification tasks.\n",
        "\n",
        "Hence, we can finetune the pretrained model in 2 ways\n",
        "\n",
        "**1. Fine-Tuning only Head (or Dense Layer)**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states\n",
        "\n",
        "\n",
        "**2. Fine-Tuning both Backbone & Head**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml6av5LqA24e",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Approach: Fine-Tuning Only Head\n",
        "\n",
        "As the name suggests, in this approach, we freeze the backbone and train only the head or dense layer.\n",
        "\n",
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients\n",
        "\n",
        "2. Define Model Architecture\n",
        "\n",
        "3. Define Optimizer and Loss\n",
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "5. Train the model\n",
        "\n",
        "6. Evaluate the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDpxm52C5mpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kF7mh9TM_Rl",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Define Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RIDAa4NF5m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert \n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "      \n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6z3HDPF5lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9R5XajGF5jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5fe402d-ea0a-4a2a-8cd8-d9954dc69184"
      },
      "source": [
        "#model architecture \n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxTyKbRUGC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# push the tensors to GPU\n",
        "sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLwIPXWNWg4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "bd72e76e-d1a5-4957-a1f8-e447b91e92d7"
      },
      "source": [
        "# understand outputs\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8960, -1.3895, -1.0712],\n",
            "        [-0.8843, -1.2947, -1.1615],\n",
            "        [-0.9099, -1.2691, -1.1509],\n",
            "        [-0.8514, -1.2819, -1.2186],\n",
            "        [-0.9650, -1.2425, -1.1076],\n",
            "        [-0.9353, -1.3501, -1.0546],\n",
            "        [-0.8627, -1.3478, -1.1452],\n",
            "        [-0.9753, -1.2643, -1.0774],\n",
            "        [-0.8849, -1.4208, -1.0620],\n",
            "        [-0.9231, -1.2884, -1.1178],\n",
            "        [-0.9613, -1.2478, -1.1073],\n",
            "        [-0.9618, -1.2306, -1.1219],\n",
            "        [-0.8743, -1.3402, -1.1361],\n",
            "        [-0.9644, -1.2575, -1.0954],\n",
            "        [-0.9228, -1.3100, -1.1003],\n",
            "        [-0.8805, -1.2835, -1.1765],\n",
            "        [-0.8361, -1.3504, -1.1793],\n",
            "        [-0.8948, -1.3033, -1.1404],\n",
            "        [-0.8801, -1.3966, -1.0853],\n",
            "        [-0.9366, -1.2906, -1.0998],\n",
            "        [-0.8680, -1.3155, -1.1652],\n",
            "        [-0.8701, -1.2654, -1.2073],\n",
            "        [-0.8920, -1.3223, -1.1281],\n",
            "        [-0.8964, -1.3177, -1.1264],\n",
            "        [-0.7724, -1.4183, -1.2175],\n",
            "        [-0.9444, -1.3060, -1.0783],\n",
            "        [-0.8942, -1.3986, -1.0668],\n",
            "        [-0.9210, -1.2643, -1.1412],\n",
            "        [-0.9566, -1.2440, -1.1161],\n",
            "        [-0.9399, -1.2842, -1.1012],\n",
            "        [-0.8473, -1.3528, -1.1617],\n",
            "        [-0.9309, -1.3419, -1.0658]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJoc1aGYN1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62c0d7c1-2d26-424c-e93e-2bb19110c95f"
      },
      "source": [
        "# no. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTdl4RZNHk4",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Define Optimizer and Loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7fjPGyQaVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Op_QSrUvem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6b06ddcf-43f7-4b72-81c0-93c933d91687"
      },
      "source": [
        "# understand the class distribution\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bat chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpluCEUzijp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1a6eaf5-642b-4bc0-b523-c01755e42dbd"
      },
      "source": [
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(labels), labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Weights: [0.53170625 1.57470152 2.06517139]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJuWGiqF5eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting a list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtirPVDg8aA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4e41828-3c24-4568-bc86-9823fb2f9108"
      },
      "source": [
        "#compute the loss\n",
        "loss = cross_entropy(outputs, target)\n",
        "print(\"Loss:\",loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(1.1441, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sx2rgyu4Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJixsg1XzHCA",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFPILeF9Spxe",
        "colab_type": "text"
      },
      "source": [
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches.\n",
        "\n",
        "During training, for each batch, we need to\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropagate Loss\n",
        "4. Update Weights \n",
        "\n",
        "Where as during evaluation, for each batch, we need to\n",
        "\n",
        "1. Perform forward pass\n",
        "2. Compute loss\n",
        "\n",
        "```\n",
        "Training: Epoch -> Batch -> Forward Pass -> Compute loss -> Backpropagate loss -> Update weights \n",
        "```\n",
        "\n",
        "```\n",
        "Evaluation: Epoch -> Batch -> Forward Pass -> Compute loss\n",
        "```\n",
        "\n",
        "Hence, for each epoch, we have a training phase and a validation phase. After each batch we need to:\n",
        "\n",
        "**Training phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Clear out the gradients calculated in the previous pass.\n",
        "\n",
        "4. Forward pass (feed input data through the network)\n",
        "\n",
        "5. Backward pass (backpropagation)\n",
        "\n",
        "6. Update parameters with optimizer.step()\n",
        "\n",
        "7. Track variables for monitoring progress\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIYKxjv2Wv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "  \n",
        "  print(\"\\nTraining.....\")  \n",
        "  \n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically. \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels)\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value \n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "  \n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SF3wrDuSwpj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Evaluation phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Forward pass (feed input data through the network)\n",
        "\n",
        "4. Compute loss on our validation data\n",
        "\n",
        "5. Track variables for monitoring progress\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPKfeGlC5_WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.      \n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7d_XacvNgyU",
        "colab_type": "text"
      },
      "source": [
        "##4.5 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sj66daFTAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da1b06d3-155a-4a0f-a7b9-491f78562d47"
      },
      "source": [
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "....... epoch 1 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:11.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:13.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:15.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:17.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:19.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.981\n",
            "Validation Loss: 0.836\n",
            "\n",
            "....... epoch 2 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.851\n",
            "Validation Loss: 0.715\n",
            "\n",
            "....... epoch 3 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.799\n",
            "Validation Loss: 0.872\n",
            "\n",
            "....... epoch 4 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.780\n",
            "Validation Loss: 0.679\n",
            "\n",
            "....... epoch 5 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.760\n",
            "Validation Loss: 0.677\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNhFJ0DANldu",
        "colab_type": "text"
      },
      "source": [
        "##4.6 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OPuAKj6Kiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2facd1d1-974d-405b-fb12-ada4b32466cc"
      },
      "source": [
        "# load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqwKsGeFTDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "bc4beb60-894a-4b7e-f7a8-da31b66a0b22"
      },
      "source": [
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "0.6771649757157201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DehF35geFTIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "y_pred = np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true = validation_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXjiXdk5Co8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "347ffba7-c2b6-4857-d91a-20c5ec3814f9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.68      0.78       918\n",
            "           1       0.51      0.65      0.57       310\n",
            "           2       0.54      0.86      0.66       236\n",
            "\n",
            "    accuracy                           0.70      1464\n",
            "   macro avg       0.65      0.73      0.67      1464\n",
            "weighted avg       0.76      0.70      0.72      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ThrTqbYo8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}